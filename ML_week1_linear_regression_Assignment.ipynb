{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-zTLHrFCT6KY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Aim is to predict the marks of students of the test data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_excel('Training data.xlsx')\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "data['internet'] = label_encoder.fit_transform(data['internet'])\n",
        "data['sex'] = label_encoder.fit_transform(data['sex'])"
      ],
      "metadata": {
        "id": "po3RplGCTYJF"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the file namd 'training data' to train the model\n",
        "\n",
        "#data = pd.read_csv('Training data.csv')\n",
        "x_train = np.array(data.iloc[:,0:8])\n",
        "y_train = np.array(data.iloc[:,8]).reshape(-1,1)\n",
        "print(type(x_train))\n",
        "\n",
        "# Try plotting y_train with different features\n",
        "# To get an idea whether to add some features or not\n",
        "# Add some features if required in x_train\n",
        "\n",
        "# Also do label encoding for features not represented in numbers\n",
        "# refer the link if not know : https://youtu.be/589nCGeWG1w?si=t2Wa7LgbUOO4RooM\n",
        "\n",
        "\n",
        "def feature_changing(x_train):\n",
        "  # ---------\n",
        "    # Your code here\n",
        "  # ---------\n",
        "  return x_train\n",
        "\n",
        "x_train = feature_changing(x_train)"
      ],
      "metadata": {
        "id": "p0KHq8ZgTpU4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f580110a-2199-4c58-e40a-32084578241b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def z_score(x_train):\n",
        "\n",
        "    x_mean = np.mean(x_train, axis=0)\n",
        "    x_std = np.std(x_train, axis=0)\n",
        "    x_train_scaled = (x_train - x_mean) / x_std\n",
        "\n",
        "    return x_train_scaled,x_std,x_mean"
      ],
      "metadata": {
        "id": "tYshvtYlVour"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(x_train_scaled,y_train,w,b):\n",
        "\n",
        "    m = len(y_train)\n",
        "    h = np.dot(x_train, w) + b\n",
        "    loss = np.mean((h - y_train) ** 2) / 2\n",
        "    return loss\n",
        "\n",
        "    return loss"
      ],
      "metadata": {
        "id": "O5dOwbNbWJWa"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(x_train,y_train,w,b, alpha):\n",
        "\n",
        "    m = len(y_train)\n",
        "    h = np.dot(x_train, w) + b\n",
        "    dw = np.dot(x_train.T, (h - y_train)) / m\n",
        "    db = np.mean(h - y_train)\n",
        "    w -= alpha * dw\n",
        "    b -= alpha * db\n",
        "\n",
        "    return w,b"
      ],
      "metadata": {
        "id": "hW8p2cTNU74W"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_linear_regression(x_train, y_train):\n",
        "    x_train = x_train\n",
        "    x_train_scaled, x_std, x_mean = z_score(x_train)\n",
        "\n",
        "    np.random.seed(2147483647)\n",
        "    w = np.random.randn(x_train_scaled.shape[1], 1)\n",
        "    b = np.random.randn(1)\n",
        "\n",
        "    old_cost = 0\n",
        "    alpha = 0.01\n",
        "\n",
        "    while True:\n",
        "        current_cost = cost(x_train_scaled, y_train, w, b)\n",
        "        if abs(old_cost - current_cost) <= 0.00001:\n",
        "            break\n",
        "        old_cost = current_cost\n",
        "        w, b = gradient_descent(x_train_scaled, y_train, w, b, alpha)\n",
        "\n",
        "    data1 = pd.read_excel('Test data.xlsx')\n",
        "    label_encoder = LabelEncoder()\n",
        "    data1['internet'] = label_encoder.fit_transform(data1['internet'])\n",
        "    data1['sex'] = label_encoder.fit_transform(data1['sex'])\n",
        "\n",
        "    x_predict = np.array(data1.iloc[:, :8])\n",
        "    x_predict_scaled = (x_predict - x_mean) / x_std\n",
        "    ans = np.array(data1.iloc[:, 8]).reshape(-1, 1)\n",
        "\n",
        "    y_predict = np.dot(x_predict_scaled, w) + b\n",
        "\n",
        "    accuracy = np.mean(np.abs(y_predict - ans) < 0.5) * 100\n",
        "\n",
        "    ok = 'Congratulations' if accuracy > 95 else 'Optimization required'\n",
        "    print(f\"{ok}, your accuracy is {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "HA6foH-NYvpU"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_linear_regression(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LyNdLlwSZMVE",
        "outputId": "33274fec-17ce-4b46-fa49-58fd3f7fa52b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Congratulations, your accuracy is 100.00%\n"
          ]
        }
      ]
    }
  ]
}